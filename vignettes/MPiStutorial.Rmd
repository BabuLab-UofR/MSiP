---
title: "MSiP tutorial"
author:
- name: "Matineh Rahmatbakhsh"
  email: matinerb.94@gmail.com
date: "`r Sys.Date()`"
package: MSiP
output: 
  BiocStyle::html_document:
    toc_float: true
vignette: >
  %\VignetteIndexEntry{MSiP tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
#Introduction
The MSiP is a computational approach to predict protein-protein
interactions (PPIs) from large-scale affinity purification mass spectrometry (AP-MS) data. This approach includes both spoke and matrix models for interpreting AP-MS data in a network context. The "spoke" model considers only bait-prey interactions, whereas the "matrix" model assumes that each of the identified proteins (baits and prey) in a given AP-MS experiment interacts with each of the others. The "spoke" model has a high false-negative rate, whereas a high positive rate has resulted from the matrix model. Thus, although both statistical models have merits, a combination of both spoke and matrix models has shown to increase the machine learning classifiers in terms of their capabilities in discrimination between true and false positive interactions [Drew et al., 2017](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5488662). 

###Installation of the developmental version from GitHub:
```{r}
##devtools::install_github(repo="Babu-lab/MSiP")
library(MSiP)
```

###Sample Data Description:
A demo AP-MS proteomics dataset is provided in this package to guide the users about data structure.
```{r}
data("SampleDatInput")
head(SampleDatInput)
```

###Scoring based on "spoke-model":
Comparative Proteomic Analysis Software Suite (CompPASS) is a robust statistical scoring scheme for assigning confidence scores to bait-prey interactions [Sowa et al., 2009](https://www.cell.com/cell/fulltext/S0092-8674(09)00503-0?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867409005030%3Fshowall%3Dtrue). The output from CompPASS scoring includes Z-score, S-score, D-score, WD-score and other features. This function was optimized from the [source code](https://github.com/zqzneptune/SMAD).  

```{r}
datScoring <- 
    cPASS(SampleDatInput)
head(datScoring)
```

###Scoring based on "matrix-model":
The Dice coefficient was first applied by [Zhang et al., 2008](https://academic.oup.com/bioinformatics/article/24/7/979/296061) to score interaction between all identified proteins (baits and preys) in a given AP-MS expriment.
```{r}
datScoring <- 
    diceCoefficient(SampleDatInput)
head(datScoring)
```

Alternatively, Jaccard, Simpson, and Overlap scores can be used to score the interaction between all the identified proteins in a given AP-MS experiment. 
```{r}
#Jaccard coefficient
datScoring <- 
    jaccardCoefficient(SampleDatInput)
head(datScoring)

#Simpson coefficient
datScoring <- 
    simpsonCoefficient(SampleDatInput)
head(datScoring)

#Overlap score
datScoring <- 
    simpsonCoefficient(SampleDatInput)
head(datScoring)
```

Finally, a weighted matrix model [Drew et al., 2017](https://www.embopress.org/doi/full/10.15252/msb.20167490) can also be employed to score interactions between identified proteins in a given AP-MS experiment. The output of the weighted matrix model includes the number of experiments for which the pair of proteins is co-purified (i.e., k) and $-1$*log(P-value) of the hypergeometric test (i.e., logHG) given the experimental overlap value, each protein's total number of observed experiments, and the total number of experiments.

```{r}
datScoring <- 
Weighted.matrixModel(SampleDatInput)
head(datScoring)
```

###Assign a confidence score to each instances using classifiers:
The labeled feature matrix can be used as input for Support Vector Machine (SVM) or random forest (RF) classifiers. The classifier then assigns each bait-prey pair a confidence score, indicating the level of support for that pair of proteins to interact. 

####Import the demo data:
```{r}
data("testdfClassifier")
head(testdfClassifier)

```

####Support Vector Machine (SVM) classifier:
```{r}
#SVM
predidcted_SV <- 
svmTrain(testdfClassifier,impute = FALSE,p = 0.3, parameterTuning = FALSE,
cost = seq(from = 2, to = 5, by = 1),
gamma = seq(from = 0.01, to = 0.10, by = 0.02),
kernel = "radial",ncross = 5,
pr.plot = TRUE, roc.plot = TRUE
)
head(predidcted_SV)
```

####Random Forest (RF) Classifier:
```{r}
#RF
predidcted_RF <- 
rfTrain(testdfClassifier,impute = FALSE, p = 0.3, parameterTuning = FALSE,
mtry  = seq(from = 1, to = 5, by = 1),
min_node_size = seq(from = 1, to = 5, by = 1),
splitrule =c("gini"),metric = "Accuracy",
resampling.method = "repeatedcv",iter = 5,repeats = 5,
pr.plot = TRUE, roc.plot = TRUE
)
head(predidcted_RF)
```




